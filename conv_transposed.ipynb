{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad5928b-5652-4501-affd-c97826186726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5e12bf6-6a40-4339-a77e-4555790ace3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(9).view(1,1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41023818-04e3-4318-8a62-ac0e51cbe719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c413fabf-a9c9-4309-b77d-50932d0ff1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1294, 0.6980, 0.0725],\n",
       "          [0.1019, 0.6675, 0.4179],\n",
       "          [0.6322, 0.7592, 0.9721]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09174841-fddc-4b75-b596-a680e8b5cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = torch.nn.ConvTranspose2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=(3,3),\n",
    "    padding=0,\n",
    "    stride=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4008c282-17de-41ce-9fbb-ac466db29a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0448,  0.1243,  0.2389],\n",
       "          [ 0.2741,  0.2558,  0.2780],\n",
       "          [ 0.0034,  0.0713, -0.1770]]]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a7e5cf0-609f-48a3-8593-2dc665c458be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2202, 0.2304, 0.2766, 0.3011, 0.3844, 0.2234, 0.2317],\n",
       "          [0.2498, 0.2475, 0.4416, 0.3929, 0.4283, 0.2329, 0.2345],\n",
       "          [0.2194, 0.2362, 0.2481, 0.3471, 0.2693, 0.2715, 0.3014],\n",
       "          [0.2423, 0.2404, 0.4256, 0.3851, 0.5145, 0.3213, 0.3305],\n",
       "          [0.2430, 0.3002, 0.3837, 0.3563, 0.3226, 0.3650, 0.3726],\n",
       "          [0.3876, 0.3761, 0.5982, 0.4086, 0.6919, 0.4631, 0.4846],\n",
       "          [0.2165, 0.2595, 0.1050, 0.2685, 0.0833, 0.2837, 0.0423]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ba37f9d-7d88-403d-b772-b75924b20ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2d = torch.nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=(3,3),\n",
    "    padding=0,\n",
    "    stride=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd4d14b8-33f3-4a23-8c52-c162aa562995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0238,  0.0812, -0.1762],\n",
       "          [ 0.0274, -0.2249, -0.0848],\n",
       "          [-0.0918, -0.0363, -0.2633]]]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2d.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e019a649-1461-4ea5-9e31-87ca0045929c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2898]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2d(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731c63a-2324-4e23-b662-cb8f84b5e1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
